{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOpzknlYI07e",
        "outputId": "613e1181-2300-4a6d-b73c-2146cb8c3b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.8/dist-packages (1.13.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.8/dist-packages (from onnx) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.8/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.1.97)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.26.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers optimum-intel evaluate neural-compressor -q\n",
        "!pip install onnx\n",
        "!pip install faiss-cpu\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbmLM-H5JBdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f592cefb-2957-4b03-c851-41454eefa37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFUijIS4H3A6"
      },
      "outputs": [],
      "source": [
        "# Allowed to make changes.\n",
        "import collections\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import timeit\n",
        "from ast import literal_eval\n",
        "import math\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "from optimum.intel.neural_compressor import INCModelForQuestionAnswering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s88yeOjL12Gv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "610f81be-bf3c-470c-d9ef-96c49741bf42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "theme Spectre_(2015_film)\n",
            "no of paragraph in theme 43\n",
            "\n",
            "\n",
            "theme To_Kill_a_Mockingbird\n",
            "no of paragraph in theme 60\n",
            "\n",
            "\n",
            "theme Kanye_West\n",
            "no of paragraph in theme 78\n",
            "\n",
            "\n",
            "theme Dog\n",
            "no of paragraph in theme 74\n",
            "\n",
            "\n",
            "theme Separation_of_powers_under_the_United_States_Constitution\n",
            "no of paragraph in theme 29\n",
            "\n",
            "\n",
            "theme Boston\n",
            "no of paragraph in theme 79\n",
            "\n",
            "\n",
            "theme University_of_Kansas\n",
            "no of paragraph in theme 36\n",
            "\n",
            "\n",
            "theme Classical_music\n",
            "no of paragraph in theme 68\n",
            "\n",
            "\n",
            "theme List_of_numbered_streets_in_Manhattan\n",
            "no of paragraph in theme 50\n",
            "\n",
            "\n",
            "theme Near_East\n",
            "no of paragraph in theme 59\n",
            "\n",
            "\n",
            "theme Wood\n",
            "no of paragraph in theme 69\n",
            "\n",
            "\n",
            "theme Mexico_City\n",
            "no of paragraph in theme 87\n",
            "\n",
            "\n",
            "theme Data_compression\n",
            "no of paragraph in theme 26\n",
            "\n",
            "\n",
            "theme Somerset\n",
            "no of paragraph in theme 37\n",
            "\n",
            "\n",
            "theme Edmund_Burke\n",
            "no of paragraph in theme 40\n",
            "\n",
            "\n",
            "theme Samoa\n",
            "no of paragraph in theme 25\n",
            "\n",
            "\n",
            "theme Nigeria\n",
            "no of paragraph in theme 55\n",
            "\n",
            "\n",
            "theme Sichuan\n",
            "no of paragraph in theme 26\n",
            "\n",
            "\n",
            "theme War_on_Terror\n",
            "no of paragraph in theme 31\n",
            "\n",
            "\n",
            "theme Labour_Party_(UK)\n",
            "no of paragraph in theme 41\n",
            "\n",
            "\n",
            "theme IBM\n",
            "no of paragraph in theme 26\n",
            "\n",
            "\n",
            "theme Friedrich_Hayek\n",
            "no of paragraph in theme 50\n",
            "\n",
            "\n",
            "theme Idealism\n",
            "no of paragraph in theme 29\n",
            "\n",
            "\n",
            "theme Cyprus\n",
            "no of paragraph in theme 58\n",
            "\n",
            "\n",
            "theme Tucson,_Arizona\n",
            "no of paragraph in theme 52\n",
            "\n",
            "\n",
            "theme Premier_League\n",
            "no of paragraph in theme 40\n",
            "\n",
            "\n",
            "theme Association_football\n",
            "no of paragraph in theme 28\n",
            "\n",
            "\n",
            "theme Light-emitting_diode\n",
            "no of paragraph in theme 43\n",
            "\n",
            "\n",
            "theme Bird\n",
            "no of paragraph in theme 60\n",
            "\n",
            "\n",
            "theme Jehovah%27s_Witnesses\n",
            "no of paragraph in theme 46\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Allowed to make changes.\n",
        "\n",
        "# Pre-processing cell. You can use this cell to pre-process input data or load\n",
        "# your models.\n",
        "import torch\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')\n",
        "# Dummy code.\n",
        "\n",
        "\n",
        "\n",
        "question_loc=r\"/content/drive/MyDrive/sample_eval_test/5_theme/sample_input_question_30.csv\"\n",
        "\n",
        "theme_loc=r\"/content/drive/MyDrive/sample_eval_test/5_theme/sample_theme_interval_30.csv\"\n",
        "\n",
        "ground_loc=r\"/content/drive/MyDrive/sample_eval_test/5_theme/sample_ground_truth_values_30.csv\"\n",
        "\n",
        "df_p=pd.read_csv(\"/content/drive/MyDrive/sample_eval_test/5_theme/sample_input_paragraph_30.csv\")\n",
        "\n",
        "# print(df_p.head(-5))\n",
        "\n",
        "theme_dict={}\n",
        "t=0\n",
        "for i in df_p[\"theme\"].unique() :\n",
        "    start=t\n",
        "    # i=j.lower()\n",
        "    print()\n",
        "    print(\"theme \"+i)\n",
        "    if(t==len(df_p)):\n",
        "            break\n",
        "    while(df_p[\"theme\"][t]==i): # use lower here if you  wish to change\n",
        "        t=t+1\n",
        "        if(t==len(df_p)):\n",
        "            break\n",
        "    theme_dict[i]={}\n",
        "    theme_dict[i][\"df\"]=df_p.iloc[start:t,:]\n",
        "    theme_dict[i][\"df\"]=theme_dict[i][\"df\"].reset_index(drop=True)\n",
        "    # key obesrvation : some theme have very less paragraph (try linear search)\n",
        "    text_vector=theme_dict[i][\"df\"][\"paragraph\"].to_list()\n",
        "    embedding_vector=embedding_model.encode(text_vector)\n",
        "    vector_length=embedding_vector.shape[1]\n",
        "    no_of_vector=embedding_vector.shape[0]\n",
        "\n",
        "    if(no_of_vector<20):\n",
        "      no_of_cell=1\n",
        "    elif(no_of_vector<100):\n",
        "      no_of_cell=10\n",
        "    else :\n",
        "      no_of_cell=20\n",
        "\n",
        "    theme_dict[i][\"quantizer_index\"]=faiss.IndexFlatL2(vector_length)\n",
        "    theme_dict[i][\"index\"] = faiss.IndexIVFFlat(theme_dict[i][\"quantizer_index\"],vector_length,no_of_cell)   # build the index\n",
        "    # print(index.is_trained)\n",
        "    theme_dict[i][\"index\"].train(embedding_vector)\n",
        "    theme_dict[i][\"index\"].add(embedding_vector)\n",
        "    theme_dict[i][\"index\"].nprobe=2\n",
        "    print(\"no of paragraph in theme \"+str(theme_dict[i][\"index\"].ntotal))\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "paragraph_ds = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "global_model_text = r\"C:\\Users\\RAJESH SOLANKI\\Desktop\\dev rev inter iit\\retrival task\\spanbert_quant\"\n",
        "\n",
        "\n",
        "# Here, you can load the existing QA pairs for themes and pre-process it.\n",
        "# Sample QA pairs: https://drive.google.com/file/d/1HORTMN3UrPyfcibMZIA6tVnkgQXlZfWn/view?usp=share_link\n",
        "questions = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8RcyC4O2DFk"
      },
      "outputs": [],
      "source": [
        "# Allowed to make changes.\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_theme_model(theme):\n",
        "  global_model=pipeline(\"question-answering\",model=\"mrm8488/spanbert-finetuned-squadv2\",tokenizer=\"mrm8488/spanbert-finetuned-squadv2\",device=0)\n",
        "  return global_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theme_dict_save = '/content/drive/MyDrive/sample_eval_test/dev_rev_test_data/test_data/theme_dict2.obj'"
      ],
      "metadata": {
        "id": "6IICyNfPA7N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "import pickle\n",
        "dbfile = open(theme_dict_save, 'wb')\n",
        "pickle.dump(theme_dict, dbfile)\n",
        "dbfile.close()"
      ],
      "metadata": {
        "id": "92P1jzmAAWve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa4x0ljoIGpP"
      },
      "outputs": [],
      "source": [
        "# Allowed to make changes.\n",
        "def pred_theme_ans(questions, theme_model, pred_out):\n",
        "  theme = questions[0][\"theme\"]\n",
        "  paragraph_dict=theme_dict[theme]\n",
        "  no_of_neighbors=1 # for sample dataset\n",
        "  if(no_of_neighbors>len(paragraph_dict[\"df\"][\"paragraph\"])):\n",
        "    no_of_neighbors=len(paragraph_dict[\"df\"][\"paragraph\"])\n",
        "    print(\"no of neighbors changed (not enough paragraph) to : \"+str(no_of_neighbors))\n",
        "\n",
        "  for question in questions:\n",
        "\n",
        "    question_embedding=embedding_model.encode([question[\"question\"]])\n",
        "\n",
        "    D, Index_of_paragraph = paragraph_dict[\"index\"].search(question_embedding, no_of_neighbors)\n",
        "\n",
        "    p_id=-1\n",
        "    ans_output=\"\"\n",
        "    ans_confidence=0\n",
        "    for i in Index_of_paragraph[0] :\n",
        "\n",
        "        if(i<0):\n",
        "          continue\n",
        "        text=paragraph_dict[\"df\"][\"paragraph\"][i]\n",
        "        #print(text)\n",
        "        ans_dictonary= theme_model({\n",
        "        'context': text,\n",
        "        'question': question[\"question\"]\n",
        "        })\n",
        "\n",
        "        # if(ans_dictonary[\"score\"]>=0.1):\n",
        "        if(ans_dictonary[\"score\"]>ans_confidence):\n",
        "          ans_confidence=ans_dictonary[\"score\"]\n",
        "          ans_output=ans_dictonary[\"answer\"]\n",
        "\n",
        "          p_id=paragraph_dict[\"df\"][\"id\"][i]\n",
        "    #-------------------------------------\n",
        "    # add your prediction methodology here.\n",
        "    #-------------------------------------\n",
        "    # Dummy method.\n",
        "    ans = {}\n",
        "    ans[\"question_id\"] = question[\"id\"]\n",
        "    ans[\"paragraph_id\"] = p_id\n",
        "    ans[\"answers\"]=ans_output\n",
        "\n",
        "    pred_out.append(ans)\n",
        "  print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4MGougaIImX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f492620-3751-40be-f001-71c315479fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectre_(2015_film)\n",
            "done\n",
            "inference time : 9486.81619600029\n",
            "To_Kill_a_Mockingbird\n",
            "done\n",
            "inference time : 4264.442852000229\n",
            "Kanye_West\n",
            "done\n",
            "inference time : 9106.311464999635\n",
            "Dog\n",
            "done\n",
            "inference time : 6418.949612999768\n",
            "Separation_of_powers_under_the_United_States_Constitution\n",
            "done\n",
            "inference time : 5159.755534999931\n",
            "Boston\n",
            "done\n",
            "inference time : 6989.805478999642\n",
            "University_of_Kansas\n",
            "done\n",
            "inference time : 7369.9062360001335\n",
            "Classical_music\n",
            "done\n",
            "inference time : 5166.059706999931\n",
            "List_of_numbered_streets_in_Manhattan\n",
            "done\n",
            "inference time : 4060.4669170002126\n",
            "Near_East\n",
            "done\n",
            "inference time : 4305.223495000064\n",
            "Wood\n",
            "done\n",
            "inference time : 5203.550633999839\n",
            "Mexico_City\n",
            "done\n",
            "inference time : 7925.897237000299\n",
            "Data_compression\n",
            "done\n",
            "inference time : 3475.819836000028\n",
            "Somerset\n",
            "done\n",
            "inference time : 7107.611318000181\n",
            "Edmund_Burke\n",
            "done\n",
            "inference time : 7042.520440000317\n",
            "Samoa\n",
            "done\n",
            "inference time : 4963.095737000003\n",
            "Nigeria\n",
            "done\n",
            "inference time : 4232.588492000104\n",
            "Sichuan\n",
            "done\n",
            "inference time : 7475.584359000095\n",
            "War_on_Terror\n",
            "done\n",
            "inference time : 6372.976611000013\n",
            "Labour_Party_(UK)\n",
            "done\n",
            "inference time : 6032.32302799961\n",
            "IBM\n",
            "done\n",
            "inference time : 4526.839146999919\n",
            "Friedrich_Hayek\n",
            "done\n",
            "inference time : 4260.655437999958\n",
            "Idealism\n",
            "done\n",
            "inference time : 5666.692237999996\n",
            "Cyprus\n",
            "done\n",
            "inference time : 4217.244389999905\n",
            "Tucson,_Arizona\n",
            "done\n",
            "inference time : 7454.048687000068\n",
            "Premier_League\n",
            "done\n",
            "inference time : 10668.166381999981\n",
            "Association_football\n",
            "done\n",
            "inference time : 4810.342911000134\n",
            "Light-emitting_diode\n",
            "done\n",
            "inference time : 8322.755648000111\n",
            "Bird\n",
            "done\n",
            "inference time : 4398.434258000179\n",
            "Jehovah%27s_Witnesses\n",
            "done\n",
            "inference time : 9550.530336000065\n",
            "{'Spectre_(2015_film)': 9486.81619600029, 'To_Kill_a_Mockingbird': 4264.442852000229, 'Kanye_West': 9106.311464999635, 'Dog': 6418.949612999768, 'Separation_of_powers_under_the_United_States_Constitution': 5159.755534999931, 'Boston': 6989.805478999642, 'University_of_Kansas': 7369.9062360001335, 'Classical_music': 5166.059706999931, 'List_of_numbered_streets_in_Manhattan': 4060.4669170002126, 'Near_East': 4305.223495000064, 'Wood': 5203.550633999839, 'Mexico_City': 7925.897237000299, 'Data_compression': 3475.819836000028, 'Somerset': 7107.611318000181, 'Edmund_Burke': 7042.520440000317, 'Samoa': 4963.095737000003, 'Nigeria': 4232.588492000104, 'Sichuan': 7475.584359000095, 'War_on_Terror': 6372.976611000013, 'Labour_Party_(UK)': 6032.32302799961, 'IBM': 4526.839146999919, 'Friedrich_Hayek': 4260.655437999958, 'Idealism': 5666.692237999996, 'Cyprus': 4217.244389999905, 'Tucson,_Arizona': 7454.048687000068, 'Premier_League': 10668.166381999981, 'Association_football': 4810.342911000134, 'Light-emitting_diode': 8322.755648000111, 'Bird': 4398.434258000179, 'Jehovah%27s_Witnesses': 9550.530336000065}\n"
          ]
        }
      ],
      "source": [
        "# NOT allowed to make changes.\n",
        "\n",
        "\n",
        "# All theme prediction.\n",
        "\n",
        "questions = json.loads(pd.read_csv(question_loc).to_json(orient=\"records\"))\n",
        "theme_intervals = json.loads(pd.read_csv(theme_loc).to_json(orient=\"records\"))\n",
        "pred_out = []\n",
        "theme_inf_time = {}\n",
        "theme_array_inf=[]\n",
        "for theme_interval in theme_intervals:\n",
        "\n",
        "  theme_ques = questions[int(theme_interval[\"start\"]) - 1: int(theme_interval[\"end\"])]\n",
        "  theme = theme_ques[0][\"theme\"]\n",
        "  # theme=theme.lower()\n",
        "  print(theme)\n",
        "  theme_array_inf.append(theme)\n",
        "  # Load model fine-tuned for this theme.\n",
        "  theme_model = get_theme_model(theme)\n",
        "  #pred_theme_ans(theme_ques, theme_model, pred_out)\n",
        "  execution_time = timeit.timeit(lambda: pred_theme_ans(theme_ques, theme_model, pred_out), number=1)\n",
        "  theme_inf_time[theme_interval[\"theme\"]] = execution_time * 1000 # in milliseconds.\n",
        "  print(\"inference time : \"+str(theme_inf_time[theme_interval[\"theme\"]]))\n",
        "pred_df = pd.DataFrame.from_records(pred_out)\n",
        "pred_df.fillna(value='', inplace=True)\n",
        "# Write prediction to a CSV file. Teams are required to submit this csv file.\n",
        "pred_df.to_csv('sample_output_prediction.csv', index=False)\n",
        "print(theme_inf_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHRMTa33I07i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d246feb0-dae3-45e7-fa69-c79221facfd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Spectre_(2015_film)': 9486.81619600029, 'To_Kill_a_Mockingbird': 4264.442852000229, 'Kanye_West': 9106.311464999635, 'Dog': 6418.949612999768, 'Separation_of_powers_under_the_United_States_Constitution': 5159.755534999931, 'Boston': 6989.805478999642, 'University_of_Kansas': 7369.9062360001335, 'Classical_music': 5166.059706999931, 'List_of_numbered_streets_in_Manhattan': 4060.4669170002126, 'Near_East': 4305.223495000064, 'Wood': 5203.550633999839, 'Mexico_City': 7925.897237000299, 'Data_compression': 3475.819836000028, 'Somerset': 7107.611318000181, 'Edmund_Burke': 7042.520440000317, 'Samoa': 4963.095737000003, 'Nigeria': 4232.588492000104, 'Sichuan': 7475.584359000095, 'War_on_Terror': 6372.976611000013, 'Labour_Party_(UK)': 6032.32302799961, 'IBM': 4526.839146999919, 'Friedrich_Hayek': 4260.655437999958, 'Idealism': 5666.692237999996, 'Cyprus': 4217.244389999905, 'Tucson,_Arizona': 7454.048687000068, 'Premier_League': 10668.166381999981, 'Association_football': 4810.342911000134, 'Light-emitting_diode': 8322.755648000111, 'Bird': 4398.434258000179, 'Jehovah%27s_Witnesses': 9550.530336000065}\n"
          ]
        }
      ],
      "source": [
        "print(theme_inf_time)\n",
        "pred_df.to_csv('sample_output_prediction.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_df.to_csv('/content/drive/MyDrive/sample_eval_test/dev_rev_test_data/test_data/update2/output_prediction.csv', index=False)\n"
      ],
      "metadata": {
        "id": "ETtya9uM8zR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lempoIKsIJ_G"
      },
      "outputs": [],
      "source": [
        "# NOT allowed to make changes.\n",
        "\n",
        "def normalize_answer(s):\n",
        "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "  def remove_articles(text):\n",
        "    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
        "    return re.sub(regex, ' ', text)\n",
        "  def white_space_fix(text):\n",
        "    return ' '.join(text.split())\n",
        "  def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return ''.join(ch for ch in text if ch not in exclude)\n",
        "  def lower(text):\n",
        "    return text.lower()\n",
        "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def get_tokens(s):\n",
        "  if not s: return []\n",
        "  return normalize_answer(s).split()\n",
        "\n",
        "def calc_f1(a_gold, a_pred):\n",
        "  gold_toks = get_tokens(a_gold)\n",
        "  pred_toks = get_tokens(a_pred)\n",
        "  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "  num_same = sum(common.values())\n",
        "  if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
        "    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "    return int(gold_toks == pred_toks)\n",
        "  if num_same == 0:\n",
        "    return 0\n",
        "  precision = 1.0 * num_same / len(pred_toks)\n",
        "  recall = 1.0 * num_same / len(gold_toks)\n",
        "  f1 = (2 * precision * recall) / (precision + recall)\n",
        "  return f1\n",
        "\n",
        "def calc_max_f1(predicted, ground_truths):\n",
        "  max_f1 = 0\n",
        "  if len(ground_truths) == 0:\n",
        "    return len(predicted) == 0\n",
        "  for ground_truth in ground_truths:\n",
        "    f1 = calc_f1(predicted, ground_truth)\n",
        "    max_f1 = max(max_f1, f1)\n",
        "  return max_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HA5KB3RIL4z"
      },
      "outputs": [],
      "source": [
        "# NOT allowed to make changes.\n",
        "\n",
        "# Evaluation methodology.\n",
        "metrics = {}\n",
        "pred = pd.read_csv(r\"sample_output_prediction.csv\")\n",
        "pred.fillna(value='', inplace=True)\n",
        "truth = pd.read_csv(ground_loc)\n",
        "truth.fillna(value='', inplace=True)\n",
        "truth.paragraph_id = truth.paragraph_id.apply(literal_eval)\n",
        "truth.answers = truth.answers.apply(literal_eval)\n",
        "questions = pd.read_csv(question_loc)\n",
        "for idx in pred.index:\n",
        "  q_id = pred[\"question_id\"][idx]\n",
        "  q_rows = questions.loc[questions['id'] == q_id].iloc[-1]\n",
        "  theme = q_rows[\"theme\"]\n",
        "  predicted_paragraph = pred[\"paragraph_id\"][idx]\n",
        "  predicted_ans = pred[\"answers\"][idx]\n",
        "\n",
        "  if theme not in metrics.keys():\n",
        "    metrics[theme] = {\"true_positive\": 0, \"true_negative\": 0, \"total_predictions\": 0, \"f1_sum\": 0}\n",
        "\n",
        "  truth_row = truth.loc[truth['question_id'] == q_id].iloc[-1]\n",
        "  truth_paragraph_id = [ int(i) for i in truth_row[\"paragraph_id\"] ]\n",
        "  # print()\n",
        "  # print(\"predicted_paragraph : \"+str(predicted_paragraph))\n",
        "  # print(truth_paragraph_id)\n",
        "  # print()\n",
        "  if predicted_paragraph in truth_paragraph_id:\n",
        "    # Increase TP for that theme.\n",
        "    metrics[theme][\"true_positive\"] = metrics[theme][\"true_positive\"] + 1\n",
        "  # -1 prediction in case there is no paragraph which can answer the query.\n",
        "  if predicted_paragraph == -1 and truth_row[\"paragraph_id\"] == []:\n",
        "    # Increase TN.\n",
        "    metrics[theme][\"true_negative\"] = metrics[theme][\"true_negative\"] + 1\n",
        "  # Increase total predictions for that theme.\n",
        "  metrics[theme][\"total_predictions\"] = metrics[theme][\"total_predictions\"] + 1\n",
        "  f1 = calc_max_f1(predicted_ans, truth_row[\"answers\"])\n",
        "  metrics[theme][\"f1_sum\"] = metrics[theme][\"f1_sum\"] + f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tuojd-v8INyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132426d9-7c9d-4eaf-83be-65501ed4c721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Spectre_(2015_film)': 0.03333333333333333, 'To_Kill_a_Mockingbird': 0.03333333333333333, 'Kanye_West': 0.03333333333333333, 'Dog': 0.03333333333333333, 'Separation_of_powers_under_the_United_States_Constitution': 0.03333333333333333, 'Boston': 0.03333333333333333, 'University_of_Kansas': 0.03333333333333333, 'Classical_music': 0.03333333333333333, 'List_of_numbered_streets_in_Manhattan': 0.03333333333333333, 'Near_East': 0.03333333333333333, 'Wood': 0.03333333333333333, 'Mexico_City': 0.03333333333333333, 'Data_compression': 0.03333333333333333, 'Somerset': 0.03333333333333333, 'Edmund_Burke': 0.03333333333333333, 'Samoa': 0.03333333333333333, 'Nigeria': 0.03333333333333333, 'Sichuan': 0.03333333333333333, 'War_on_Terror': 0.03333333333333333, 'Labour_Party_(UK)': 0.03333333333333333, 'IBM': 0.03333333333333333, 'Friedrich_Hayek': 0.03333333333333333, 'Idealism': 0.03333333333333333, 'Cyprus': 0.03333333333333333, 'Tucson,_Arizona': 0.03333333333333333, 'Premier_League': 0.03333333333333333, 'Association_football': 0.03333333333333333, 'Light-emitting_diode': 0.03333333333333333, 'Bird': 0.03333333333333333, 'Jehovah%27s_Witnesses': 0.03333333333333333}\n",
            "\n",
            "total inference time for that theme : 9486.81619600029   total no of question   320\n",
            "avg inference time : 29.64630061250091\n",
            "qa score without accounting time for that theme :0.38503472222222224\n",
            "\n",
            "total inference time for that theme : 4264.442852000229   total no of question   166\n",
            "avg inference time : 25.68941477108572\n",
            "qa score without accounting time for that theme :0.6545467584624212\n",
            "\n",
            "total inference time for that theme : 9106.311464999635   total no of question   280\n",
            "avg inference time : 32.52254094642727\n",
            "qa score without accounting time for that theme :0.6290590465435187\n",
            "\n",
            "total inference time for that theme : 6418.949612999768   total no of question   275\n",
            "avg inference time : 23.341634956362793\n",
            "qa score without accounting time for that theme :0.7579419404125286\n",
            "\n",
            "total inference time for that theme : 5159.755534999931   total no of question   161\n",
            "avg inference time : 32.048171024844294\n",
            "qa score without accounting time for that theme :0.3336783988957902\n",
            "\n",
            "total inference time for that theme : 6989.805478999642   total no of question   240\n",
            "avg inference time : 29.124189495831843\n",
            "qa score without accounting time for that theme :0.8400901875901877\n",
            "\n",
            "total inference time for that theme : 7369.9062360001335   total no of question   242\n",
            "avg inference time : 30.45415800000055\n",
            "qa score without accounting time for that theme :0.3989651533039963\n",
            "\n",
            "total inference time for that theme : 5166.059706999931   total no of question   216\n",
            "avg inference time : 23.916943087962643\n",
            "qa score without accounting time for that theme :0.6959130375797042\n",
            "\n",
            "total inference time for that theme : 4060.4669170002126   total no of question   145\n",
            "avg inference time : 28.003220117242844\n",
            "qa score without accounting time for that theme :0.6721182266009852\n",
            "\n",
            "total inference time for that theme : 4305.223495000064   total no of question   170\n",
            "avg inference time : 25.32484408823567\n",
            "qa score without accounting time for that theme :0.6249944018829469\n",
            "\n",
            "total inference time for that theme : 5203.550633999839   total no of question   230\n",
            "avg inference time : 22.62413319130365\n",
            "qa score without accounting time for that theme :0.677536231884058\n",
            "\n",
            "total inference time for that theme : 7925.897237000299   total no of question   279\n",
            "avg inference time : 28.408233824373834\n",
            "qa score without accounting time for that theme :0.6859785908331131\n",
            "\n",
            "total inference time for that theme : 3475.819836000028   total no of question   146\n",
            "avg inference time : 23.806985178082382\n",
            "qa score without accounting time for that theme :0.26666123070232656\n",
            "\n",
            "total inference time for that theme : 7107.611318000181   total no of question   230\n",
            "avg inference time : 30.902657904348615\n",
            "qa score without accounting time for that theme :0.24665841390873283\n",
            "\n",
            "total inference time for that theme : 7042.520440000317   total no of question   259\n",
            "avg inference time : 27.191198610039834\n",
            "qa score without accounting time for that theme :0.32661546947261233\n",
            "\n",
            "total inference time for that theme : 4963.095737000003   total no of question   175\n",
            "avg inference time : 28.360547068571446\n",
            "qa score without accounting time for that theme :0.4658503401360545\n",
            "\n",
            "total inference time for that theme : 4232.588492000104   total no of question   180\n",
            "avg inference time : 23.514380511111693\n",
            "qa score without accounting time for that theme :0.7960756835756834\n",
            "\n",
            "total inference time for that theme : 7475.584359000095   total no of question   236\n",
            "avg inference time : 31.67620491101735\n",
            "qa score without accounting time for that theme :0.2882814219678626\n",
            "\n",
            "total inference time for that theme : 6372.976611000013   total no of question   252\n",
            "avg inference time : 25.289589726190528\n",
            "qa score without accounting time for that theme :0.33561725972440254\n",
            "\n",
            "total inference time for that theme : 6032.32302799961   total no of question   190\n",
            "avg inference time : 31.749068568419\n",
            "qa score without accounting time for that theme :0.2142397660818713\n",
            "\n",
            "total inference time for that theme : 4526.839146999919   total no of question   186\n",
            "avg inference time : 24.33784487634365\n",
            "qa score without accounting time for that theme :0.4051419906258616\n",
            "\n",
            "total inference time for that theme : 4260.655437999958   total no of question   148\n",
            "avg inference time : 28.788212418918636\n",
            "qa score without accounting time for that theme :0.6846525096525097\n",
            "\n",
            "total inference time for that theme : 5666.692237999996   total no of question   199\n",
            "avg inference time : 28.47584039195978\n",
            "qa score without accounting time for that theme :0.3557788944723618\n",
            "\n",
            "total inference time for that theme : 4217.244389999905   total no of question   171\n",
            "avg inference time : 24.66224789473629\n",
            "qa score without accounting time for that theme :0.776380766731644\n",
            "\n",
            "total inference time for that theme : 7454.048687000068   total no of question   259\n",
            "avg inference time : 28.780110760618022\n",
            "qa score without accounting time for that theme :0.7464493323515882\n",
            "\n",
            "total inference time for that theme : 10668.166381999981   total no of question   371\n",
            "avg inference time : 28.75516545013472\n",
            "qa score without accounting time for that theme :0.4298271796593604\n",
            "\n",
            "total inference time for that theme : 4810.342911000134   total no of question   193\n",
            "avg inference time : 24.92405653367945\n",
            "qa score without accounting time for that theme :0.3980789504105566\n",
            "\n",
            "total inference time for that theme : 8322.755648000111   total no of question   271\n",
            "avg inference time : 30.71127545387495\n",
            "qa score without accounting time for that theme :0.3969155076166146\n",
            "\n",
            "total inference time for that theme : 4398.434258000179   total no of question   167\n",
            "avg inference time : 26.337929688623827\n",
            "qa score without accounting time for that theme :0.6809873858421265\n",
            "\n",
            "total inference time for that theme : 9550.530336000065   total no of question   305\n",
            "avg inference time : 31.313214216393657\n",
            "qa score without accounting time for that theme :0.3417516379241255\n",
            "final paragraph pridiction score :0.5085265737639215\n",
            "final qa score :0.5170606812355925\n"
          ]
        }
      ],
      "source": [
        "# NOT allowed to make changes.\n",
        "\n",
        "# Final score.\n",
        "inf_time_threshold = 1000.0 # milliseconds.\n",
        "final_para_score = 0.0\n",
        "final_qa_score = 0.0\n",
        "# Weight would stay hidden from teams.\n",
        "#theme_weights = {\"Kubernetes\": 0.5, \"ChatGPT\": 0.4, \"Football world cup\": 0.1}\n",
        "# theme_weights = {\"Uranium\": 0.2, \"Bill_%26_Melinda_Gates_Foundation\": 0.2, \"Somerset\": 0.2, \"Rule_of_law\": 0.2, \"Bird\": 0.2}\n",
        "theme_weights = {}\n",
        "\n",
        "for i in theme_array_inf:\n",
        "  theme_weights[i]=1/len(theme_array_inf)\n",
        "\n",
        "print(theme_weights)\n",
        "\n",
        "for theme in metrics:\n",
        "  inf_time_score = 1.0\n",
        "  metric = metrics[theme]\n",
        "  para_score = (metric[\"true_positive\"] + metric[\"true_negative\"]) / metric[\"total_predictions\"]\n",
        "  qa_score = metric[\"f1_sum\"] / metric[\"total_predictions\"]\n",
        "  avg_inf_time = theme_inf_time[theme] / metric[\"total_predictions\"]\n",
        "  print()\n",
        "  print(\"total inference time for that theme : \"+str(theme_inf_time[theme])+\"   total no of question   \"+str(metric[\"total_predictions\"]))\n",
        "  print(\"avg inference time : \"+str(avg_inf_time))\n",
        "  print(\"qa score without accounting time for that theme :\"+str(qa_score))\n",
        "  if avg_inf_time > inf_time_threshold:\n",
        "\n",
        "    inf_time_score = inf_time_threshold / avg_inf_time\n",
        "  final_qa_score += theme_weights[theme] * inf_time_score * qa_score\n",
        "  final_para_score += theme_weights[theme] * inf_time_score * para_score\n",
        "print (\"final paragraph pridiction score :\"+str(final_para_score))\n",
        "print (\"final qa score :\"+str(final_qa_score))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pt-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "04308a1de12811478e85ab0fae54493d485a1cc02a3c88a4916ea0fdcbd54402"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}